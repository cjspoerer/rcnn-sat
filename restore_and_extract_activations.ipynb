{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from rcnn_sat import preprocess_image\n",
    "from rcnn_sat.bl_net import bl_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore model and extract activations\n",
    "This example shows how to extract activations from a pre-trained model. We'll use the BL model trained on eco-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build the graph for the model using a placeholder for the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Courtney\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input((128, 128, 3))\n",
    "model = bl_net(input_layer, classes=565, cumulative_readout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All model functions take an input layer as the first argument and the number of classes as the second. Note for ecoset `classes=565` and for ImageNet `classes=1000`.\n",
    "\n",
    "BL has an additional argument specifying whether or not to use a cumulative readout. By deafult `cumulative_readout=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the weights\n",
    "Download the pre-trained weights for the models from OSF (weights for other models can be found [here](https://osf.io/mz9hw/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: nginx\n",
      "Date: Fri, 10 May 2019 09:11:49 GMT\n",
      "Content-Type: application/octet-stream\n",
      "Content-Length: 112560228\n",
      "Content-Disposition: attachment; filename=\"bl_ecoset.h5\"; filename*=UTF-8''bl_ecoset.h5\n",
      "X-Waterbutler-Request-Id: d9e83d84-eb01-4da8-803e-dec5ed80955a\n",
      "Cache-Control: no-cache, no-store, max-age=0, must-revalidate\n",
      "Expires: Mon, 01 Jan 1990 00:00:00 GMT\n",
      "Pragma: no-cache\n",
      "Via: 1.1 google\n",
      "Alt-Svc: clear\n",
      "Connection: close\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, msg = urllib.request.urlretrieve(\n",
    "    'https://osf.io/9td5p/download', 'bl_ecoset.h5')\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bl_ecoset.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract activations\n",
    "\n",
    "To get the activation in Keras we need to know the name of the layer. The name of the output at each layer and time step has the format `ReLU_Layer_{layer_index}_Time_{time_index}`. So, the output of the first layer on the third time step is labelled `ReLU_Layer_0_Time_2` (note that zero-indexing is used).\n",
    "\n",
    "We use this to create a function mapping from input to output that we call to get a numpy array of the layer activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_activation = tf.keras.backend.function(\n",
    "    [model.input],\n",
    "    [model.get_layer('ReLU_Layer_0_Time_2').output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get the activations based on a random image. We scale the image into the correct range for the pre-trained networks by passing the image through `preprocess_image`. The image must be in `uint8` format (values in the range `[0, 255]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[0.        , 0.        , 0.        , ..., 0.20635995,\n",
       "           1.0930816 , 0.5146626 ],\n",
       "          [0.92382973, 0.1553492 , 0.04881164, ..., 0.42562833,\n",
       "           0.35726875, 0.14409715],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.2982943 , 0.24723515],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           2.3006628 , 0.        ],\n",
       "          [0.        , 0.        , 0.13931724, ..., 0.        ,\n",
       "           1.5231669 , 0.10467729],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.00790107,\n",
       "           0.        , 0.7055516 ],\n",
       "          [3.1366339 , 1.4123831 , 0.        , ..., 0.        ,\n",
       "           0.34940588, 0.5651195 ],\n",
       "          [0.        , 0.33985692, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02948871, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.8805397 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.63162655, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[2.0095525 , 3.388814  , 0.        , ..., 0.        ,\n",
       "           0.        , 0.0163824 ],\n",
       "          [0.        , 1.4395859 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.7951452 , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.41080242, 0.        , ..., 0.        ,\n",
       "           0.        , 0.20975715],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.14397971, 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.35092348, 0.        ],\n",
       "          [0.        , 0.        , 1.3389733 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.50993407, 0.84510905, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.09128962, ..., 0.        ,\n",
       "           0.        , 0.7367765 ],\n",
       "          [0.9933241 , 0.09910244, 0.        , ..., 0.        ,\n",
       "           0.        , 0.6327677 ],\n",
       "          [0.        , 0.1965946 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.81869984],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.6275913 , 0.75344026, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.94267815, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 2.3151226 , ..., 0.        ,\n",
       "           0.        , 0.63490677],\n",
       "          [1.222391  , 1.6038613 , 0.        , ..., 0.        ,\n",
       "           0.        , 0.8857813 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.8483448 ],\n",
       "          ...,\n",
       "          [0.        , 0.86713964, 0.        , ..., 0.        ,\n",
       "           0.06732632, 0.        ],\n",
       "          [0.6177391 , 0.        , 0.        , ..., 0.        ,\n",
       "           0.6801207 , 0.        ],\n",
       "          [0.        , 0.        , 0.6912964 , ..., 0.        ,\n",
       "           0.        , 0.36156878]]]], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_img = np.random.randint(0, 256, (1, 128, 128, 3), dtype=np.uint8)\n",
    "preprocessed_img = preprocess_image(random_img)\n",
    "get_layer_activation(preprocessed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
